#################################USER_SERVICE BEGIN########################
USER_SERVICE{
	akka {
		actor.provider = "akka.cluster.ClusterActorRefProvider"
	  	extensions = ["akka.contrib.pattern.ClusterReceptionistExtension"]
		extensions = ["akka.contrib.pattern.DistributedPubSubExtension"]
	  	remote {
	    	log-remote-lifecycle-events = off
	    	netty.tcp = ${akka.remote.netty.tcp}
	    	netty.tcp {
	      		hostname = "127.0.0.1"
	      		port = 8005
	   		}
	   	}
  	}
	camel {
	    # Whether JMX should be enabled or disabled for the Camel Context
	    jmx = off
	    # enable/disable streaming cache on the Camel Context
	    streamingCache = on
	    consumer {
	      # Configured setting which determines whether one-way communications
	      # between an endpoint and this consumer actor
	      # should be auto-acknowledged or application-acknowledged.
	      # This flag has only effect when exchange is in-only.
	      auto-ack = on

	      # When endpoint is out-capable (can produce responses) reply-timeout is the
	      # maximum time the endpoint can take to send the response before the message
	      # exchange fails. This setting is used for out-capable, in-only,
	      # manually acknowledged communication.
	      reply-timeout = 1m

	      # The duration of time to await activation of an endpoint.
	      activation-timeout = 10s
    	}
	    #Scheme to FQCN mappings for CamelMessage body conversions
	    conversions {
	      "file" = "java.io.InputStream"
		}
	}
}
#################################USER_SERVICE END########################
#################################DB BEGIN########################
DB{
	akka {
	  actor.provider = "akka.cluster.ClusterActorRefProvider"
	  extensions = ["akka.contrib.pattern.ClusterReceptionistExtension"]
	  extensions = ["akka.contrib.pattern.DistributedPubSubExtension"]
	  remote {
	    log-remote-lifecycle-events = off
	    netty.tcp = ${akka.remote.netty.tcp}
	    netty.tcp {
	      hostname = "127.0.0.1"
	      port = 8004
	    }
	  }
	}
}
#################################DB END########################
#################################SHARDING BEGIN########################
SHARDING{
	akka {
	  actor.provider = "akka.cluster.ClusterActorRefProvider"
	  extensions = ["akka.contrib.pattern.ClusterReceptionistExtension"]
	  extensions = ["akka.contrib.pattern.DistributedPubSubExtension"]
	  remote {
	    log-remote-lifecycle-events = off
	    netty.tcp = ${akka.remote.netty.tcp}
	    netty.tcp {
	      hostname = "192.168.0.118"
	      port = 8008
	    }
	  }
	}
}
#################################SHARDING END########################
#################################FRONTIO BEGIN########################
FRONTIO{
	akka {
	  actor.provider = "akka.cluster.ClusterActorRefProvider"
	  extensions = ["akka.contrib.pattern.ClusterReceptionistExtension"]
	  extensions = ["akka.contrib.pattern.DistributedPubSubExtension"]
	  remote {
	    log-remote-lifecycle-events = off
	    netty.tcp = ${akka.remote.netty.tcp}
	    netty.tcp {
	      hostname = "127.0.0.1"
	      port = 8003
	    }
	  }
	}
}
#################################FRONTIO END########################
#################################KING BEGIN#########################
KING{
	akka {
  		actor.provider = "akka.cluster.ClusterActorRefProvider"
  		extensions = ["akka.contrib.pattern.ClusterReceptionistExtension"]
  		extensions = ["akka.contrib.pattern.DistributedPubSubExtension"]
  		remote {
			log-remote-lifecycle-events = off
			netty.tcp = ${akka.remote.netty.tcp}
			netty.tcp {
				hostname = "127.0.0.1"
      			port = 10000
    		}
  		}
  	}
}
#################################KING END##########################
#################################OVERLORD BEGIN########################
OVERLORD{
	akka {
	  actor.provider = "akka.cluster.ClusterActorRefProvider"
	  extensions = ["akka.contrib.pattern.ClusterReceptionistExtension"]
	  extensions = ["akka.contrib.pattern.DistributedPubSubExtension"]
	  remote {
		  	log-remote-lifecycle-events = off
		  	netty.tcp = ${akka.remote.netty.tcp}
		    netty.tcp {
		    hostname = "127.0.0.1"
		    port = 8002
		    }
	  }
	}
}
#################################OVERLORD END########################
#################################MONSTER BEGIN########################
MONSTER{
	akka {
	  actor.provider = "akka.cluster.ClusterActorRefProvider"
	  extensions = ["akka.contrib.pattern.ClusterReceptionistExtension"]
	  extensions = ["akka.contrib.pattern.DistributedPubSubExtension"]
	  remote {
	    	log-remote-|lifecycle-events = off
	    	netty.tcp = ${akka.remote.netty.tcp}
	   		netty.tcp {
	      	hostname = "127.0.0.1"
	      	port = 8001
	  		}
	  }
	}
}
#################################MONSTER END########################

#################################akka.contrib.cluster.receptionist BEGIN###############
 # //#receptionist-ext-config
  # Settings for the ClusterReceptionistExtension
  akka.contrib.cluster.receptionist {
  # Actor name of the ClusterReceptionist actor, /user/receptionist
  name = receptionist
  # Start the receptionist on members tagged with this role.
  # All members are used if undefined or empty.
  role = ""

  # The receptionist will send this number of contact points to the client
  number-of-contacts = 1

  # The actor that tunnel response messages to the client will be stopped
  # after this time of inactivity.
  response-tunnel-receive-timeout = 30s
}
# //#receptionist-ext-config
#################################akka.contrib.cluster.receptionist END###############
#################################akka.contrib.cluster.pub-sub START###############
# Settings for the DistributedPubSubExtension
akka.contrib.cluster.pub-sub {
# Actor name of the mediator actor, /user/distributedPubSubMediator
name = distributedPubSubMediator
# Start the mediator on members tagged with this role.
# All members are used if undefined or empty.
role = ""
# How often the DistributedPubSubMediator should send out gossip information
gossip-interval = 1s
# Removed entries are pruned after this duration
removed-time-to-live = 5s
}
#################################akka.contrib.cluster.pub-sub END###############
#################################akka.cluster BEGIN###############
akka.cluster{
	auto-down = off
	auto-down-unreachable-after = 1200s
	jmx.enable = off
	log-info = off
}
#################################akka.cluster END################
#################################akka.actor.serializers BEGIN##############
akka.actor{
	serializers {
		java = "akka.serialization.JavaSerializer"
		proto = "akka.remote.serialization.ProtobufSerializer"
	}
	serialization-bindings {
		"java.lang.String" = java
		"docs.serialization.Customer" = java
		"com.i4joy.akka.kok.io.protocol.Packet" = proto
		"com.i4joy.akka.kok.db.protobufs.KOKDBPacket" = proto
		"com.i4joy.akka.kok.protobufs.KOKPacket" = proto
	}
}
#################################akka.actor.serializers END##############
#################################akka.io BEGIN#################
akka.io{
	pinned-dispatcher {
		type = "PinnedDispatcher"
		executor = "thread-pool-executor"
		thread-pool-executor.allow-core-pool-timeout = off
	}
	tcp {
		# The number of selectors to stripe the served channels over; each of
		# these will use one select loop on the selector-dispatcher.
		nr-of-selectors = 8
		# Maximum number of open channels supported by this TCP module; there is
		# no intrinsic general limit, this setting is meant to enable DoS
		# protection by limiting the number of concurrently connected clients.
		# Also note that this is a "soft" limit; in certain cases the implementation
		# will accept a few connections more or a few less than the number configured
		# here. Must be an integer > 0 or "unlimited".
		max-channels = 2560000
		# When trying to assign a new connection to a selector and the chosen
		# selector is at full capacity, retry selector choosing and assignment
		# this many times before giving up
		selector-association-retries = 16
		# The maximum number of connection that are accepted in one go,
		# higher numbers decrease latency, lower numbers increase fairness on
		# the worker-dispatcher
		batch-accept-limit = 64
		# The number of bytes per direct buffer in the pool used to read or write
		# network data from the kernel.
		direct-buffer-size = 51200 KiB
		# The maximal number of direct buffers kept in the direct buffer pool for
		# reuse.
		direct-buffer-pool-limit = 20000
		# The duration a connection actor waits for a ‘Register‘ message from
		# its commander before aborting the connection.
		register-timeout = 10s
		# The maximum number of bytes delivered by a ‘Received‘ message. Before
		# more data is read from the network the connection actor will try to
		# do other work.
		max-received-message-size = unlimited
		# Enable fine grained logging of what goes on inside the implementation.
		# Be aware that this may log more than once per message sent to the actors
		# of the tcp implementation.
		trace-logging = off
		# Fully qualified config path which holds the dispatcher configuration
		# to be used for running the select() calls in the selectors
		selector-dispatcher = "akka.io.pinned-dispatcher"
		# Fully qualified config path which holds the dispatcher configuration
		# for the read/write worker actors
		worker-dispatcher = "akka.actor.default-dispatcher"
		# Fully qualified config path which holds the dispatcher configuration
		# for the selector management actors
		management-dispatcher = "akka.actor.default-dispatcher"
		# Fully qualified config path which holds the dispatcher configuration
		# on which file IO tasks are scheduled
		file-io-dispatcher = "akka.actor.default-dispatcher"
		# The maximum number of bytes (or "unlimited") to transfer in one batch
		# when using ‘WriteFile‘ command which uses ‘FileChannel.transferTo‘ to
		# pipe files to a TCP socket. On some OS like Linux ‘FileChannel.transferTo‘
		# may block for a long time when network IO is faster than file IO.
		# Decreasing the value may improve fairness while increasing may improve
		# throughput.
		file-io-transferTo-limit = 20480 KiB
		# The number of times to retry the ‘finishConnect‘ call after being notified about
		# OP_CONNECT. Retries are needed if the OP_CONNECT notification doesn’t imply that
		# ‘finishConnect‘ will succeed, which is the case on Android.
		finish-connect-retries = 5
	}
}
#################################akka.io END##################
#################################akka.remote.netty.tcp START###########
akka.remote.netty.tcp{
# Sets the high water mark for the in and outbound sockets,
				# set to 0b for platform default
				write-buffer-high-water-mark = 25600000b
				# Sets the low water mark for the in and outbound sockets,
				# set to 0b for platform default
				write-buffer-low-water-mark = 2560000b
				# Sets the send buffer size of the Sockets,
				# set to 0b for platform default
				send-buffer-size = 2560000b
				# Sets the receive buffer size of the Sockets,
				# set to 0b for platform default
				receive-buffer-size = 2560000b
				# Maximum message size the transport will accept, but at least
				# 32000 bytes.
				# Please note that UDP does not support arbitrary large datagrams,
				# so this setting has to be chosen carefully when using UDP.
				# Both send-buffer-size and receive-buffer-size settings has to
				# be adjusted to be able to buffer messages of maximum size.
				maximum-frame-size = 1280000b
				# Sets the size of the connection backlog
				backlog = 10240
				# Enables the TCP_NODELAY flag, i.e. disables Nagle’s algorithm
				tcp-nodelay = on
				# Enables TCP Keepalive, subject to the O/S kernel’s configuration
				tcp-keepalive = on
				# Used to configure the number of I/O worker threads on server sockets
				server-socket-worker-pool {
					# Min number of threads to cap factor-based number to
					pool-size-min = 16
					# The pool size factor is used to determine thread pool size
					# using the following formula: ceil(available processors * factor).
					# Resulting size is then bounded by the pool-size-min and
					# pool-size-max values.
					pool-size-factor = 4.0
					# Max number of threads to cap factor-based number to
					pool-size-max = 16
				}
				# Used to configure the number of I/O worker threads on client sockets
				client-socket-worker-pool {
					# Min number of threads to cap factor-based number to
					pool-size-min = 16
					# The pool size factor is used to determine thread pool size
					# using the following formula: ceil(available processors * factor).
					# Resulting size is then bounded by the pool-size-min and
					# pool-size-max values.
					pool-size-factor = 4.0
					# Max number of threads to cap factor-based number to
					pool-size-max = 16
				}
}
#################################akka.remote.netty.tcp END###########